#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=28
#SBATCH -t 01:00:00
#SBATCH --job-name="pipeline_phylogatr"
#SBATCH --account=PAS1604

set -xe

export WORKDIR=${WORKDIR:-/fs/project/PAS1604/pipeline/dev}

export GENBANK_DIR=/fs/project/PAS1604/genbank
export GBIF_PATH=/fs/project/PAS1604/gbif/0147211-200613084148143.filtered.txt
export GBIF_PATH_EXPANDED=/fs/project/PAS1604/gbif/0147211-200613084148143.filtered.txt.expanded

cd $SLURM_SUBMIT_DIR

module load pcp
module load ruby

function expand_gbif_occurrences {
    if [[ -f $GBIF_PATH_EXPANDED ]]; then
        echo "Using expanded GBIF file at $GBIF_PATH_EXPANDED"
        cp $GBIF_PATH_EXPANDED $TMPDIR/gbif_occurrences.csv.sorted
    else
        # FIXME: if the expanded gbif file is not sorted, the linking of the two files will fail silently
        # either test and verify, and leave below as is
        # or change the expansion code to build the file in memory before writing or write to tmp file and then sort tmp to final dest
        bin/rake pipeline:expand_gbif_occurrences_on_accession GBIF=$GBIF_PATH GBIF_OUT=$TMPDIR/gbif_occurrences.csv
        sort -k 1b,1 $TMPDIR/gbif_occurrences.csv > $TMPDIR/gbif_occurrences.csv.sorted
        cp $TMPDIR/gbif_occurrences.csv.sorted $GBIF_PATH_EXPANDED
    fi
}

function link_occurrence_and_genes {
    export GBIF_PATH_EXPANDED=$TMPDIR/gbif_occurrences.csv.sorted

    # takes 20m - a lot of time lost in bin/rake setup - could switch this to bin/db or add a bin/pipeline thor script
    for i in $GENBANK_DIR/gb{inv,mam,pln,pri,rod,vrt}*seq
    do
        echo "OUTPUT_DIR=$TMPDIR GENBANK_PATH=$i bin/rake pipeline:link_gbif_with_genbank"
    done | srun parallel-command-processor

    # FIXME: parallelizing tasks doesn't work with multitask but may with https://github.com/grosser/parallel_tests
    # 38m on 40 items (so it really isn't doing parallelism (just using threads)
    # (time GBIF_PATH_EXPANDED=$TMPDIR/gbif_occurrences.csv.sorted OUTPUT_DIR=$TMPDIR bin/rake -m pipeline:link_gbif_with_genbank)
}

function collect_files {
    cat $TMPDIR/*.genes.tsv.occurrences > $TMPDIR/gbif.tsv
    cat $TMPDIR/*.genes.tsv > $TMPDIR/genes.tsv
}

function create_genes_directory {
    mkdir $TMPDIR/genes
    cat $TMPDIR/genes.tsv | ruby genes.rb $TMPDIR/genes
    (cd $TMPDIR; tar czf genes.tar.gz genes)
}

function copy_results_to_output_dir {
    cp $TMPDIR/genes.tar.gz $TMPDIR/genes.tsv $TMPDIR/gbif.tsv $WORKDIR
}

if [[ -f $WORKDIR/genes.tsv && -f $WORKDIR/gbif.tsv && -f $WORKDIR/genes.tar.gz ]]
then
    echo "Using already generated genes.tsv, gbif.tsv, and genes.tar.gz"
else
    time expand_gbif_occurrences
    time link_occurrence_and_genes
    time collect_files
    time create_genes_directory
    time copy_results_to_output_dir
fi
