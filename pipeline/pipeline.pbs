#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=28
#SBATCH -t 01:00:00
#SBATCH --job-name="pipeline_phylogatr"
#SBATCH --account=PAS1604

set -xe

export OUTPUT_DIR=/fs/scratch/PAS1604/genbank

export GENBANK_DIR=/fs/project/PAS1604/genbank
export GBIF_PATH=/fs/project/PAS1604/gbif/0147211-200613084148143.filtered.txt
export INDEXES_CACHE_DIR=/fs/scratch/PAS1604/genbank_indexes

cd $SLURM_SUBMIT_DIR

# Steps
# 1. given original gbif occurrences tsv, expand on accessions column so there is 1 accession per row

module load pcp
module load ruby
module load python/3.6-conda5.2
source activate local

function generate_indexes_and_occurrence_files {
    split -d -n 27 $GBIF_PATH $TMPDIR/x
    ls -1 $TMPDIR/x* | \
        ruby -ne 'puts %Q[invoke expand-occurrences #{$_.strip} #{$_.strip}.expanded]' | \
        srun parallel-command-processor
    cat $TMPDIR/x*expanded > $TMPDIR/gbif_occurrences.csv
    rm $TMPDIR/x*

    sort -k 1b,1 $TMPDIR/gbif_occurrences.csv > $TMPDIR/gbif_occurrences.csv.sorted

    # 2. in parallel for each genbank .seq flatfile
    #    1. make index
    #    2. join on accession
    ls -1 "$GENBANK_DIR"/gb{inv,mam,pln,pri,rod,vrt}*seq | \
        ruby -ne 'puts %Q[#{ENV["PBS_O_WORKDIR"]}/generate_index_and_accessions_files.sh #{ENV["TMPDIR"]}/gbif_occurrences.csv.sorted #{$_.strip} #{ENV["TMPDIR"]}]' > $TMPDIR/gen_index_cmds

    srun parallel-command-processor $TMPDIR/gen_index_cmds
}

if [[ -d $INDEXES_CACHE_DIR ]]; then
    echo "Using index from cache at $INDEXES_CACHE_DIR"
    cp -r $INDEXES_CACHE_DIR/* $TMPDIR
else
    echo "Generating index files"
    time generate_indexes_and_occurrence_files
    mkdir -p $INDEXES_CACHE_DIR
    cp $TMPDIR/*idx $TMPDIR/*idx.occurrences $INDEXES_CACHE_DIR
fi


#    3. for each relevant accession, read flatfile format sequence data and corresponding occurrence record and:
#       1. append organism to last column if genbank organism differs from occurrence record taxonomy, or empty string
#       2. write occurrence record with new column to a new output file
#       3. create directory to store sequence data
#       4. for each gene, use lookup to get gene short name for gene, then create directory and write gene and sequences as files
#       5. write gene metadata record to file

ls -1 "$GENBANK_DIR"/gb{inv,mam,pln,pri,rod,vrt}*seq | \
    ruby -ne 'puts %Q[invoke write-genes #{ENV["TMPDIR"]}/#{File.basename($_.strip)}.idx.occurrences #{$_.strip} #{ENV["TMPDIR"]}]' > $TMPDIR/run_pipeline_cmds

srun parallel-command-processor $TMPDIR/run_pipeline_cmds


function add_incrementing_index_column_to_file {
    awk '{ print NR "\t" $0  }'
}


# 4. cat all gene files together into 1
cat $TMPDIR/*.genes.tsv.occurrences > $TMPDIR/gbif_occurrences_final.tsv
cat $TMPDIR/*.genes.tsv > $TMPDIR/genes.tsv

# 5. get rid of occurrences and genes that do not have 3 genes or more
cut -f1 $TMPDIR/genes.tsv | sort | uniq -c | sort -n | ruby -ne 'puts $_.strip if($_.to_i > 2)' | cut -d ' ' -f2 | sort -k 1b,1 > $TMPDIR/genes_with_gt2_seqs
invoke trim-genes-and-occurrences-by-fasta-paths $TMPDIR/genes.tsv $TMPDIR/gbif_occurrences_final.tsv $TMPDIR/genes_with_gt2_seqs


cp $TMPDIR/gbif_occurrences_final.tsv.trimmed $OUTPUT_DIR/gbif_occurrences_final.tsv

# 6. create $OUTPUT/ genes/, genes.tar.gz, and genes.tsv
mv $TMPDIR/genes.tsv.trimmed $TMPDIR/genes.tsv
mkdir $TMPDIR/genes

# copy cache (this is regenerated after alignments)
cp $OUTPUT_DIR/genes.db $TMPDIR/genes.db

# create the directory structure from the genes.tsv file
# FIXME: genes.rb should use the cache to write the fa files, not the alignment
# commands below - or have a separate script for updating alignments
#
cat $TMPDIR/genes.tsv | ruby genes.rb $TMPDIR/genes

# add back alignments from cache
# update alignall file for what needs aligned
#FIXME: needs_aligned needs to have this $OUTPUT_DIR replace the $TMPDIR using sed
ruby generate_alignment_commands.rb $TMPDIR/genes $TMPDIR/genes.db > $OUTPUT_DIR/needs_aligned

# sync genes
# create tarball for future use
cd $TMPDIR
tar czf genes.tar.gz genes
cp genes.tar.gz $OUTPUT_DIR

#FIXME: this previously did not work
# rsync -a --ignore-times --delete genes $OUTPUT_DIR/genes

cp genes.tsv $OUTPUT_DIR/genes.tsv
